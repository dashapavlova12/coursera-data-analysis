{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Ubuntu Linux)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "task-3.3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2MCw8PpgMCqV",
        "colab_type": "text"
      },
      "source": [
        "# Ансамблевые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sjt2GfrhMCqW",
        "colab_type": "text"
      },
      "source": [
        "## Задача классификации "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2XliM-wrMCqX",
        "colab_type": "text"
      },
      "source": [
        "В этом практическом задании вы научитесь работать с ансамблевыми моделями. Мы начнем с задачи классификации итальянского вина на предмет его пренадлежности к одному из трех видов. Загрузите датасет `Wine Data Database` с помощью функции `load_wine` из модуля `sklearn.datasets`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V3VX7ASMCqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "X, y = load_wine(return_X_y=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GhdqTs-qMCqc",
        "colab_type": "text"
      },
      "source": [
        "Модель случайного леса для классификации представлена классом `RandomForestClassifier` из модуля `sklearn.ensemble`. Конструктор этого класса содержит аргумент `n_estimators`, который соответствует колличеству базовых алгоритмов в случайном лесе. Целью этого задания будет настройка этого параметра. Сравните модели случайных лесов с различным числом базовых алгоритмов `{1, 5, 10, 20}`. Что происходит с качеством случайного леса на тестовых данных при увеличении этого числа? Ответом на это задание `answer1` является лучшая оценка качества модели, округленная до трех знаков после запятой. Используйте `accuracy` как метрику качества и скользящий контроль `cross_val_score` как метод оценки качества модели. Установите параметр `cv = StratifiedKFold(4)`. Возьмите среднее значение оценки качества. Для каждой из моделей случайного леса используете `random_state=42` при создании нового экземпляра."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "taJsyRDbMCqd",
        "colab_type": "text"
      },
      "source": [
        "### *РЕШЕНИЕ*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yhNLBHzMCqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "wine = load_wine()\n",
        "rand_forest = RandomForestClassifier(n_estimators = 20,random_state=42)\n",
        "X_train, X_test,y_train, y_test = train_test_split(wine.data, wine.target, random_state=42, test_size = 0.3, stratify = wine.target)\n",
        "model = rand_forest.fit(X_train, y_train)\n",
        "cv = StratifiedKFold(4)\n",
        "score = cross_val_score(model, wine.data, wine.target, scoring = 'accuracy', cv =cv)\n",
        "answer1 = score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-DuEats-MCqg",
        "colab_type": "text"
      },
      "source": [
        "Далее сравните модель градиентного бустинга `GradientBoostingClassifier` из `sklearn.ensemble` с логистической регрессией `LogisticRegression` из `sklearn.linear_model` на этой выборке. Используете параметр `random_state=42` при создании экземпляров классов. Какая из моделей работает лучше? Приведите лучшую оценку, округленную до трех знаков после запятой, в качестве ответа `answer2` на это задание. Какие выводы из этого можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LH_WhJQFMCqh",
        "colab_type": "text"
      },
      "source": [
        "### *РЕШЕНИЕ*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx3GyYP4MCqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "18d2a219-e5c1-4b39-819e-2faab446fbd2"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "grad_boost = GradientBoostingClassifier(random_state = 42)\n",
        "log_reg = LogisticRegression(random_state = 42)\n",
        "model_grad = grad_boost.fit(X_train, y_train)\n",
        "cv = StratifiedKFold(4)\n",
        "score_grad = cross_val_score(model_grad, wine.data, wine.target, scoring = 'accuracy', cv =cv)\n",
        "model_log = log_reg.fit(X_train, y_train)\n",
        "cv = StratifiedKFold(4)\n",
        "score_log = cross_val_score(model_log, wine.data, wine.target, scoring = 'accuracy', cv =cv)\n",
        "answer2 = score_log.mean()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "NA6nP20qMCqk",
        "colab_type": "text"
      },
      "source": [
        "## Задача регрессии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "M6ytFMqJMCqk",
        "colab_type": "text"
      },
      "source": [
        "Загрузите уже известную вам выборку `Boston House Prices` и разделите ее случайным образом на тренировочную и тестовую выборку. Для этого используете функцию `train_test_split` с параметрами `random_state=54` и `test_size=0.33`. Мы будем сравнивать 4 модели: `RandomForestRegressor`, `GradientBoostingRegressor` из `sklearn.ensemble`, а так же Гребневую регрессию и ЛАССО (`Ridge`, `Lasso` из `sklearn.linear_model`). Обучите каждую модель на тренировочной выборке с параметром `random_state=42` в конструкторе. Какая из моделей показывает наименьшее значение среднеквадратической ошибки на тестовых данных? В качестве ответа `answer3` приведите это значение, округленное до двух цифр после запятой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rhvmR1v2MCql",
        "colab_type": "text"
      },
      "source": [
        "### *РЕШЕНИЕ*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_G1HsKqMCql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b505171b-3b01-4c1d-a7e5-f7db2510cbe8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "boston = load_boston()\n",
        "X_train, X_test,y_train, y_test = train_test_split(boston.data, boston.target, random_state=54, test_size = 0.33)#, stratify = boston.target)\n",
        "rand_forest = RandomForestRegressor(random_state = 42)\n",
        "model_forest = rand_forest.fit(X_train, y_train)\n",
        "pred_f = model_forest.predict(X_test)\n",
        "error_f = mean_squared_error(pred_f,y_test)\n",
        "grad_boost = GradientBoostingRegressor(random_state = 42)\n",
        "model_boost = grad_boost.fit(X_train, y_train)\n",
        "pred_b = model_boost.predict(X_test)\n",
        "error_b = mean_squared_error(pred_b,y_test)\n",
        "ridge = Ridge(random_state = 42)\n",
        "model_ridge = ridge.fit(X_train, y_train)\n",
        "pred_r = model_ridge.predict(X_test)\n",
        "error_r = mean_squared_error(pred_r,y_test)\n",
        "lasso = Lasso(random_state = 42)\n",
        "model_lasso = lasso.fit(X_train, y_train)\n",
        "pred_l = model_lasso.predict(X_test)\n",
        "error_l = mean_squared_error(pred_l,y_test)\n",
        "print(error_f,error_b,error_r,error_l)\n",
        "answer3 = error_b"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.484614479041907 8.53545069144848 23.795716055531496 26.91706168967631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AxBJWmNhMCqo",
        "colab_type": "text"
      },
      "source": [
        "# Строка с ответами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7zlLQpMCqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "15bbda1f-e95d-4cc1-856e-807793ce6baf"
      },
      "source": [
        "output = \"\"\"Best score (random forest) {0:.3f}\n",
        "Best score (other algorithms) {1:.3f}\n",
        "Best score (regression) {2:.2f}\"\"\"\n",
        "print(output.format(answer1, answer2, answer3))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score (random forest) 0.972\n",
            "Best score (other algorithms) 0.956\n",
            "Best score (regression) 8.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SAFWGCbTh8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
